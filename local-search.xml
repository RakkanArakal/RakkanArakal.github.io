<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Pod图形化展开</title>
    <link href="/2023/02/17/Pod%E5%9B%BE%E5%BD%A2%E5%8C%96%E5%B1%95%E5%BC%80/"/>
    <url>/2023/02/17/Pod%E5%9B%BE%E5%BD%A2%E5%8C%96%E5%B1%95%E5%BC%80/</url>
    
    <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>最近接触到Iscca gym,MuJoCo这类的物理引擎可以在linux中尝试实时渲染，但我们的镜像运行在云端kubernetes，没有可用的图形化界面，直接导出数据再渲染的方式会有一定的滞后性。如果既想使用我们性能强大的gpu进行运算，又想直观地看到实时反馈，唯一的解决办法就是打通Pod到本地的图形渲染管道。</p><h2 id="X协议">X协议</h2><p>Linux本身是没有图形化界面的，所谓的图形化界面系统只不过中 Linux 下的应用程序。这一点和 Windows 不一样。Windows 从 Windows 95 开始，图形界面就直接在系统内核中实现了，是操作系统不可或缺的一部分。Linux 的图形化界面，底层都是基于 X 协议。</p><p><img src="/img/pod_1.png" alt="img"></p><p>把X server和X client抽象成windows上的 主机 + 显示器 。</p><p>我们看到的显示器+键鼠就是X client ，供我们交互。而Pod上的linux系统就是X server 。</p><p>我们要做的是在Pod上开放x11 forwarding供本地连接。</p><h2 id="x11-forwarding">x11 forwarding</h2><h4 id="远程服务器端"><strong>远程服务器端</strong></h4><p>在Linux打开x11 Fording:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs Bash">sudo vim /etc/ssh/sshd_config<br><br>/**************************/<br><span class="hljs-comment"># 配置转发参数（自己手动修改）</span><br>X11Forwarding <span class="hljs-built_in">yes</span><br>X11DisplayOffset 10<br>/****配置完毕后重启ssh服务****/<br><br>service ssh restart<br></code></pre></td></tr></table></figure><h4 id="本地客户端">本地客户端</h4><p>macOS安装<strong>xquartz</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">brew install --cask xquartz<br></code></pre></td></tr></table></figure><p>安装好后位置比较隐蔽，第一次打开的时候找了很久，在应用程序 -&gt; 实用工具（工具） -&gt; xquartz</p><p><img src="!%5Bimg%5D(https://docimg1.docs.qq.com/image/AgAABTJcxKr7q-IkEe9KergOkMU4Q_MO.png?w=1374&amp;h=184)" alt="img"></p><p>在打开的命令行窗口中输入ssh连接指令连接即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Bash">ssh -X 你的名字@你的地址<br><br>（比如 ssh -X rakkanhong@someAddress）<br></code></pre></td></tr></table></figure><p>windows安装<strong>MobaXterm：</strong></p><p>MobaXterm 是一款开源免费的、全功能终端软件，自带 X Server。下载地址如下：</p><p><a href="https://mobaxterm.mobatek.net/download.html">MobaXterm free Xserver and tabbed SSH client for Windows</a></p><p>安装成功后同样在终端输入ssh连接指令链接即可</p><h4 id="测试连接">测试连接</h4><p>连接成功之后，输入xclock测试：</p><ul><li><h2 id="如果X11-Forwarding没有成功开启的话，会显示-Error-Can’t-open-display">如果X11 Forwarding没有成功开启的话，会显示 Error: Can’t open display:</h2></li><li>如果成功开启，会展示出一个时钟的页面<ul><li><img src="/img/pod_2.png" alt="img"></li></ul></li></ul><p>看到这个界面就大功告成了</p><h2 id="Kubernetes开启ssh连接">Kubernetes开启ssh连接</h2><p>正常能够通过ssh连接的服务器到上面已经结束了，但我们的Pod是通过kubectl exec的方式进入容器，并不是通过ssh进行远程访问的，这里有一篇关于两种不同连接方式的对比<a href="https://blog.csdn.net/NewTyun/article/details/108525876">SSH vs.kubectl exec_新钛云服的博客-CSDN博客</a>。</p><p>由于这种方式实现的连接没有建立起ssh隧道，Pod中的DISPLAY仍然为空，即使是手动进行设置也没办法进行工作，所以想要尝试使用ssh的方式连入Pod。</p><p>实际的操作其实也并不复杂，需要首先要在Pod里安装开启ssh服务，接着另外增加一个用户用于连接（Pod里初始的root没有初始密码，而且增加了密码之后尝试也没有连接成功）。使用port-forward功能将Pod的22端口forward至本地指定端口，再通过ssh的方法进行连接：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment">## port-forward</span><br>kubectl port-forward pods/jupyter-rakkanhong 10086:22 -n tensorpipes<br><br><span class="hljs-comment">##ssh</span><br>ssh -X testuser@localhost -p 10086<br></code></pre></td></tr></table></figure><p>连通后输入netstat -nltp确实可以看到22端口已经开启监听，但查看DISPLAY参数仍然为空，尝试失败。</p><p>最终尝试了一下VNC Server 并且连接成功。</p><h2 id="VNC">VNC</h2><p>VNC (Virtual Network Console)是一款基于 UNIX 和 Linux 操作系统的优秀远程控制工具软件，由著名的 AT&amp;T 的欧洲研究实验室开发，远程控制能力强大，高效实用，并且免费开源。</p><p>不同于使用X11 forwarding在连接成功后就能自动将X Client当做$DISPLAY来显示图像，VNC需要连接在服务器中现有的图形界面。所以我们需要借助到Xvfb和x11vnc来搭建虚拟X Server供我们本地连接。</p><h4 id="远程服务器端-2"><strong>远程服务器端</strong></h4><p>首先在一个终端中启动一个虚拟屏幕：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">Xvfb :1 -ac -screen 0 960x540x24<br></code></pre></td></tr></table></figure><p>启动完毕后这个终端之后保持在后台不要关闭，另起一个终端运行x11vnc:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">x11vnc -display :1 <br></code></pre></td></tr></table></figure><p>可以在终端中看到详细的log信息，同时可以看到5900的端口已经打开，需要将该端口forward到本地，在vscode中会自动进行Port-forward，如果需要手动forward的话需要在本地输入以下指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Bash">kubectl port-forward pods/&#123;pod名&#125; &#123;本地端口&#125;:5900 -n &#123;namespace名&#125;<br><br>（比如 kubectl port-forward pods/jupyter-rakkanhong 10086:5900 -n tensorpipes )<br></code></pre></td></tr></table></figure><p>当然如果不是在Pod里的话，直接使用服务器IP+端口就行了，连接起来比上面的ssh还要方便。</p><h4 id="本地客户端-2">本地客户端</h4><p>Windows和macOS都可以用下述链接下载VNC Server</p><p><a href="https://www.realvnc.com/en/connect/download/vnc/">Download VNC Server | VNC® Connect</a></p><p>安装后打开VNC Viewer，输入localhost:{本地端口}后就能跑通了，不过注意此时的连接方式是相当于投屏的方式进行展示。具体需要展示的东西需要在远程绑定了前面虚拟出来的DISPLAY后才能在本地看见。例如新建一个终端后输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment">#设置DISPLAY,注意引号内的编号为之前xvfb所设置的编号</span><br><span class="hljs-built_in">export</span> DISPLAY=<span class="hljs-string">&quot;:1&quot;</span><br>xclock<br></code></pre></td></tr></table></figure><p><img src="/img/pod_3.png" alt="img"></p><p>可以看到本地的Viewver已经成功显示出所连接的远程桌面了，自此成功打通Pod上的图形展开。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">apt-get install build-essential freeglut3 freeglut3-dev binutils-gold<br></code></pre></td></tr></table></figure><h2 id="参考链接">参考链接</h2><p>[通过X11实现 Linux服务器图形化界面显示 - 李晓春 - 博客园](<a href="https://www.cnblogs.com/lixiaochun/p/8547815.html#:~:text=X">https://www.cnblogs.com/lixiaochun/p/8547815.html#:~:text=X</a> 协议由 X server 和 X client 组成：,client。 l X client (即 X 应用程序) 则主要负责事件的处理（即程序的逻辑）。)</p><p><a href="https://blog.csdn.net/Longyu_wlz/article/details/128068675?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~AD_ESQUERY~yljh-1-128068675-blog-107871367.pc_relevant_aa2&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~AD_ESQUERY~yljh-1-128068675-blog-107871367.pc_relevant_aa2&amp;utm_relevant_index=2">macOS 使用 X11 运行远端 linux 中的 x11 client 图形程序_mac x11_longyu_wlz的博客-CSDN博客</a></p><p><a href="https://zhuanlan.zhihu.com/p/268648649">如何从集群外部通过SSH进入Kubernetes Pod ？</a></p><p><a href="https://blog.csdn.net/qq_36383272/article/details/114970803">xvfb与x11vnc_天空中的野鸟的博客-CSDN博客_xvfb</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>技术</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>人体3D姿态数据集</title>
    <link href="/2023/02/13/%E4%BA%BA%E4%BD%933D%E5%A7%BF%E6%80%81%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <url>/2023/02/13/%E4%BA%BA%E4%BD%933D%E5%A7%BF%E6%80%81%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<h1><strong>Recovering 3D Human Mesh from Monocular Images: A Survey</strong></h1><h3 id="数据集整理">数据集整理</h3><p><img src="/img/dataset_1.png" alt=""></p><table><thead><tr><th><strong>Rendered Datasets</strong></th><th></th><th></th></tr></thead><tbody><tr><td>SURREAL Dataset</td><td><a href="https://www.di.ens.fr/willow/research/surreal/data/">https://www.di.ens.fr/willow/research/surreal/data/</a></td><td>数据集包含600万帧合成人体数据</td></tr><tr><td>GTA-Human</td><td><a href="https://github.com/open-mmlab/mmhuman3d/tree/main/configs/gta_human">https://github.com/open-mmlab/mmhuman3d/tree/main/configs/gta_human</a></td><td>20K带有SMPL注释的视频序列。</td></tr><tr><td>AGORA</td><td><a href="https://agora.is.tue.mpg.de/">https://agora.is.tue.mpg.de/</a></td><td>超过4000个逼真的纹理人体扫描放置在全景场景</td></tr><tr><td>THUman2.0</td><td><a href="https://github.com/ytrock/THuman2.0-Dataset">https://github.com/ytrock/THuman2.0-Dataset</a></td><td>包含来自单个 RGBD 传感器的 6k（200 个受试者 x 30 个姿势）扫描，带有 SMPL 注释。</td></tr><tr><td>MultiHuman</td><td><a href="https://github.com/zhangyux15/multiview_human_dataset">https://github.com/zhangyux15/multiview_human_dataset</a></td><td>包含453个高质量的3D人体扫描,每个扫描包含1-3人在封闭或交互场景下</td></tr><tr><td><strong>Marker/Sensor-based MoCap</strong></td><td></td><td></td></tr><tr><td>HumanEva</td><td><a href="http://humaneva.is.tue.mpg.de/">http://humaneva.is.tue.mpg.de/</a></td><td>包括HumanEva- i和HumanEva- ii。这两个数据集是在一个多摄像头动作捕捉系统。在受试者身上贴上反射标记，以记录4名受试者在HumanEva-I中执行6个动作，2名受试者在HumanEva-II中执行1个动作。</td></tr><tr><td>Human3.6M</td><td><a href="http://vision.imar.ro/human3.6m/description.php">http://vision.imar.ro/human3.6m/description.php</a></td><td>包含360万个3D人体姿势图像，11名专业演员，17个场景</td></tr><tr><td>3DPW</td><td><a href="https://virtualhumans.mpi-inf.mpg.de/3DPW/">https://virtualhumans.mpi-inf.mpg.de/3DPW/</a></td><td>60个视频序列,包括7名演员共18种服装风格的51000多帧画面</td></tr><tr><td><strong>Marker-less Multi-view MoCap</strong></td><td></td><td></td></tr><tr><td>CMU Panoptic</td><td><a href="http://domedb.perception.cs.cmu.edu/">http://domedb.perception.cs.cmu.edu/</a></td><td>由Panoptic Studio中的480台同步摄像机捕获的大规模多人数据集</td></tr><tr><td>MPI-INF-3DHP</td><td><a href="https://github.com/alisa-yang/mpi_inf_3dhp">https://github.com/alisa-yang/mpi_inf_3dhp</a></td><td>在多摄像头绿屏工作室中收集的单人3D姿态数据集</td></tr><tr><td>MuCo-3DHP</td><td><a href="https://paperswithcode.com/dataset/muco-3dhp">https://paperswithcode.com/dataset/muco-3dhp</a></td><td>上述数据集的补充</td></tr><tr><td>MuPoTS-3D</td><td><a href="https://paperswithcode.com/dataset/mupots-3d">https://paperswithcode.com/dataset/mupots-3d</a></td><td>由8000多个帧组成，涵盖5个室内和15个室外设置</td></tr><tr><td>MannequinChallenge</td><td><a href="https://google.github.io/mannequinchallenge/www/index.html">https://google.github.io/mannequinchallenge/www/index.html</a></td><td>许多人都一动不动地摆着这个姿势，摄像机四处移动，拍摄静态场景</td></tr><tr><td>3DOH50K</td><td><a href="https://www.yangangwang.com/papers/ZHANG-OOH-2020-03.html">https://www.yangangwang.com/papers/ZHANG-OOH-2020-03.html</a></td><td>采集于6个视点的室内场景。包含超过51600张图像</td></tr><tr><td>Mirrored-Human</td><td><a href="https://github.com/zju3dv/Mirrored-Human">https://github.com/zju3dv/Mirrored-Human</a></td><td>镜面人，提供2d关键点</td></tr><tr><td>MTC</td><td><a href="http://domedb.perception.cs.cmu.edu/mtc.html">http://domedb.perception.cs.cmu.edu/mtc.html</a></td><td>包含大约834K的身体图像和111K的手部图像</td></tr><tr><td>EHF</td><td><a href="https://smpl-x.is.tue.mpg.de">https://smpl-x.is.tue.mpg.de</a></td><td></td></tr><tr><td>HUMBI</td><td><a href="https://github.com/zhixuany/HUMBI">https://github.com/zhixuany/HUMBI</a></td><td>107个同步高清相机被用来捕捉772个不同的对象</td></tr><tr><td>ZJU-MoCap</td><td><a href="https://chingswy.github.io/Dataset-Demo/">https://chingswy.github.io/Dataset-Demo/</a></td><td>由21个同步摄像机在多视图设置中捕获的9个动态人类序列组成</td></tr><tr><td><strong>Datasets with Pseudo-3D Labels</strong></td><td></td><td></td></tr><tr><td>LSP</td><td><a href="https://paperswithcode.com/dataset/lsp">https://paperswithcode.com/dataset/lsp</a></td><td>包含从Flickr收集的2，000张运动员图像，每个图像都带有 14 个关节位置的注释</td></tr><tr><td>LSP-extended</td><td><a href="https://dbcollection.readthedocs.io/en/latest/datasets/leeds_sports_pose_extended.html">https://dbcollection.readthedocs.io/en/latest/datasets/leeds_sports_pose_extended.html</a></td><td>扩展的 LSP 数据集包含额外的 10000 张标记为训练的图像</td></tr><tr><td>PennAction</td><td><a href="https://github.com/dreamdragon/PennAction">https://github.com/dreamdragon/PennAction</a></td><td>包含 15 个不同动作的 2326 个视频序列,每个序列带有人体关节注释</td></tr><tr><td>MSCOCO</td><td><a href="https://paperswithcode.com/dataset/coco">https://paperswithcode.com/dataset/coco</a></td><td>由 328K 图像组成，超过 39000 张图像和 56000 个用 DensePose 注释标记的人</td></tr><tr><td>MPII</td><td><a href="https://humanshape.mpi-inf.mpg.de/">https://humanshape.mpi-inf.mpg.de/</a></td><td>包含约 25K图像，其中对超过4万名人体进行关节标注</td></tr><tr><td>UP-3D</td><td><a href="https://files.is.tuebingen.mpg.de/classner/up/#datasets">https://files.is.tuebingen.mpg.de/classner/up/#datasets</a></td><td>结合了两个 LSP 数据集（11，000 张训练图像和 1，000 张测试图像）和 MPII-HumanPose 数据集的单人部分（13，030 张训练图像和 2622 张测试图像）。</td></tr><tr><td>PoseTrack</td><td><a href="https://paperswithcode.com/dataset/posetrack">https://paperswithcode.com/dataset/posetrack</a></td><td>包含 514 个视频，总共 66374 帧</td></tr><tr><td>SSP-3D</td><td><a href="https://github.com/akashsengupta1997/SSP-3D">https://github.com/akashsengupta1997/SSP-3D</a></td><td>由311张野外照片组成的，照片中有62名穿着紧身衣的运动员</td></tr><tr><td>OCHuman</td><td><a href="https://paperswithcode.com/dataset/ochuman">https://paperswithcode.com/dataset/ochuman</a></td><td>包含 5081 张图像中的 13360 个精心注释的人类实例</td></tr><tr><td>MTP</td><td><a href="https://tuch.is.tue.mpg.de/">https://tuch.is.tue.mpg.de/</a></td><td>包含3,731张图像，对应1,653个SMPL-X网格</td></tr></tbody></table><p><img src="/img/dataset_2.png" alt=""></p><h1>关于<strong>human reconstruction</strong>的一些额外补充</h1><table><thead><tr><th>BUFF</th><th><a href="https://www.researchgate.net/figure/BUFF-Dataset-To-validate-our-method-we-captured-a-new-dataset-including-6-subjects_fig2_314943320">https://www.researchgate.net/figure/BUFF-Dataset-To-validate-our-method-we-captured-a-new-dataset-including-6-subjects_fig2_314943320</a></th><th>具有真实 3D 形状的服装人员的高质量 4D 数据集。BUFF数据集由5名受试者组成，3名男性和2名女性穿着2种服装风格</th></tr></thead><tbody><tr><td>Twindom</td><td><a href="https://web.twindom.com/human-3d-body-scan-dataset-for-research-from-3d-scans/">https://web.twindom.com/human-3d-body-scan-dataset-for-research-from-3d-scans/</a></td><td>2000 个匿名、带注释的全身 3D 模型**(收费)**</td></tr></tbody></table><h1><strong>M</strong>otion Capture</h1><table><thead><tr><th>AMASS</th><th><a href="https://amass.is.tue.mpg.de/">https://amass.is.tue.mpg.de/</a></th><th>超过 40 小时的运动数据，涵盖 300 多个主题，超过 11000 个动作</th></tr></thead><tbody><tr><td>HumanML3D and KIT</td><td><a href="https://github.com/EricGuoICT/HumanML3D">https://github.com/EricGuoICT/HumanML3D</a></td><td>HumanML3D是一个3D人体运动语言数据集，源自<a href="https://github.com/EricGuo5513/action-to-motion">HumanAct12</a>和<a href="https://github.com/EricGuo5513/action-to-motion">Amass</a>数据集的组合HumanML3D 数据集由 <strong>14616</strong> 个动作和 <strong>44970</strong> 个描述组成，由 <strong>5371</strong> 个不同的单词组成。动议总时长为<strong>28.59</strong>小时。平均动作长度为 <strong>7.1</strong> 秒，而平均描述长度为 <strong>12</strong> 个单词</td></tr><tr><td>KIT-ML</td><td><a href="https://motion-annotation.humanoids.kit.edu/dataset/">https://motion-annotation.humanoids.kit.edu/dataset/</a></td><td>包含 3911 个动作和 6278 个描述。按照与 HumanML3D 数据集相同的过程处理 KIT-ML 数据集</td></tr><tr><td>UESTC RGB-D</td><td><a href="https://paperswithcode.com/dataset/uestc-rgb-d">https://paperswithcode.com/dataset/uestc-rgb-d</a></td><td>UESTC RGB-D 变视图动作数据库包含 40 类有氧运动。我们利用 2 个 Kinect V2 摄像头在 8 个固定方向和 1 个圆形方向上捕捉这些动作，并使用 RGB 视频、3D 骨架序列和深度图序列的数据模式来捕捉这些动作。</td></tr><tr><td>BABEL</td><td><a href="https://babel.is.tue.mpg.de/">https://babel.is.tue.mpg.de/</a></td><td>BABEL由来自<a href="https://github.com/EricGuo5513/action-to-motion">Amass</a>的约43小时动作捕捉序列的动作标签组成，BABEL 中有超过 28k 个序列标签和 63k 帧标签，它们属于 250 多个独特的动作类别。来自 BABEL 的标签可用于动作识别、时间动作定位、运动合成等任务。</td></tr><tr><td>PoseScript</td><td><a href="https://europe.naverlabs.com/research/computer-vision/posescript/">https://europe.naverlabs.com/research/computer-vision/posescript/</a></td><td>PoseScript 是一个数据集，它将来自 AMASS 的几千个 3D 人体姿势与身体部位及其空间关系的丰富人工注释描述配对。此数据集旨在从大规模数据集中检索相关姿势和合成姿势生成，两者都基于文本姿势描述。</td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>数据集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>二月一日刷题打卡</title>
    <link href="/2023/02/01/02-01_leetcode/"/>
    <url>/2023/02/01/02-01_leetcode/</url>
    
    <content type="html"><![CDATA[<h2 id="力扣2325-解密消息">力扣2325:解密消息</h2><blockquote><p>给你字符串 key 和 message ，分别表示一个加密密钥和一段加密消息。解密 message 的步骤如下：</p><p>使用 key 中 26 个英文小写字母第一次出现的顺序作为替换表中的字母 顺序 。<br>将替换表与普通英文字母表对齐，形成对照表。<br>按照对照表 替换 message 中的每个字母。<br>空格 ’ ’ 保持不变。<br>例如，key = “happy boy”（实际的加密密钥会包含字母表中每个字母 至少一次），据此，可以得到部分对照表（‘h’ -&gt; ‘a’、‘a’ -&gt; ‘b’、‘p’ -&gt; ‘c’、‘y’ -&gt; ‘d’、‘b’ -&gt; ‘e’、‘o’ -&gt; ‘f’）。<br>返回解密后的消息。</p><p>输入：key = “the quick brown fox jumps over the lazy dog”, message = “vkbs bs t suepuv”<br>输出：“this is a secret”<br>解释：对照表如上图所示。<br>提取 “the quick brown fox jumps over the lazy dog” 中每个字母的首次出现可以得到替换表。</p></blockquote><p>今天的题目是一套简单题，不过很久没写代码了，原来想用vector简单解决，后面觉得还是map比较简单，从解答方式倒过来写了一下加入字典的方式，跑代码的时候修改了一下map的key属性，很快就出来了。</p><p>第一次出来的答案不太对劲，对比了一下发现是空字符串没有加到字典导致字母错了一位，把这个问题修复了就得到答案了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">string <span class="hljs-title">decodeMessage</span><span class="hljs-params">(string key, string message)</span> </span>&#123;<br>        unordered_map&lt;<span class="hljs-type">char</span>,string&gt; map;<br>        <span class="hljs-type">int</span> flag = <span class="hljs-number">0</span>;<br>        map[<span class="hljs-string">&#x27; &#x27;</span>] = <span class="hljs-string">&quot; &quot;</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> c:key)&#123;<br>            <span class="hljs-keyword">if</span>(map.<span class="hljs-built_in">count</span>(c) == <span class="hljs-number">0</span>)&#123;<br>                map[c] = flag + <span class="hljs-string">&#x27;a&#x27;</span>;<br>                flag ++;<br>            &#125;<br>        &#125;<br>        string ret = <span class="hljs-string">&quot;&quot;</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> c:message)&#123;<br>            ret += map[c];<br>        &#125;<br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>写完了觉得太快了，顺便看了一下python的题解，也是用了字典的方式解决，学习了一下基本算背了出来。以后也要稍微熟悉一下python的刷题方法，最好的条件是两种语言都能用上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decodeMessage</span>(<span class="hljs-params">self, key, message</span>):<br>        s = <span class="hljs-string">&quot;abcdefghijklmnopqrstuvwxyz&quot;</span>  <br>        d = &#123;<span class="hljs-string">&quot; &quot;</span>:<span class="hljs-string">&quot; &quot;</span>&#125;<br>        i = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> key:<br>            <span class="hljs-keyword">if</span> c <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> d:<br>                d[c] = s[i]<br>                i += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>.join(d[c] <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> message)<br></code></pre></td></tr></table></figure><p>今天的学习到此结束。</p>]]></content>
    
    
    
    <tags>
      
      <tag>刷题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于AI绘图技术的360度贴图生成</title>
    <link href="/2023/01/23/%E5%9F%BA%E4%BA%8EAI%E7%BB%98%E5%9B%BE%E6%8A%80%E6%9C%AF%E7%9A%84360%E5%BA%A6%E8%B4%B4%E5%9B%BE%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F/"/>
    <url>/2023/01/23/%E5%9F%BA%E4%BA%8EAI%E7%BB%98%E5%9B%BE%E6%8A%80%E6%9C%AF%E7%9A%84360%E5%BA%A6%E8%B4%B4%E5%9B%BE%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h1>基于AI绘图技术的360度贴图生成</h1><h2 id="项目流程图">项目流程图</h2><p><img src="https://notes.sjtu.edu.cn/uploads/upload_88145f7d70d9f616f8c373f2fa4f3f1c.png" alt=""></p><h2 id="Unity客户端部分">Unity客户端部分</h2><p>采用Unity提供的自定义Editor的方式，编写Unity编辑器插件，实现上传文字prompt和选择图片上传到服务器后端的功能。</p><p>对于服务器返回的图片，实现了自定义Asset的导入流程，使图片自动转化为可以被直接使用的天空盒Material。在运行时实现了读取目录下Material并供用户选择的功能。</p><h2 id="后端服务部分">后端服务部分</h2><p>基于Python的Flask框架实现。接收客户端发来的文字或者图片，经过BLIP、CLIP（文字提取）、Text2Light（全景图生成）、stable-diffusion（局部细节修复）等模型，生成一张与原图相关联的全景图，并返回给客户端。</p><h2 id="Text2Light">Text2Light</h2><p>全景图不同于一般风景图像视野有限，可以看作是360度球面场。这一约束是全景图生成的基础，模型中引入了球形位置编码来表示360度场景。将全景图上的像素映射到球面上的一点上，保证了结构的完整<br><img src="https://notes.sjtu.edu.cn/uploads/upload_0335bc9001960b8d564f2402a1359a75.png" alt=""></p><p>模型主要有三个部分，首先构建双码本，对于512*1024的全景图，下采样成128*256来构建表示整体外观和语义的全局码本<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>，从全景图中随机裁取256*256的补丁来构建表示局部细粒度特征的局部码本<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">Z_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<br><img src="https://notes.sjtu.edu.cn/uploads/upload_6014afd01d32d121d5777cd6297ed0e9.png" alt=""></p><p>第二部分是以输入文本为条件，在全局码本中采样整体语义。使用CLIP的文本编码器和图像编码器，训练时通过扰动图像特征生成伪文本特征，文本条件采样器从给定输入文本的全局码本<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>中采样整体特征，以自回归的方式训练全局采样器，采样器会预测可能的下一个指标s的分布，使得文本对齐采样器的可能性最大化，在推理过程中，直接使用真实文本特征，得到整体条件<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">z_g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>。<br><img src="https://notes.sjtu.edu.cn/uploads/upload_d26a0760ef81b1a0588d8e8e00a2d843.png" alt=""></p><p>最后在整体条件的指导下，逐片合成结构感知的全景图。具体的说，就是从局部码本<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">Z_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中采样特征。在给定整体条件<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">z_g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>的情况下，合成对应球形位置编码的局部碎片。<br><img src="https://notes.sjtu.edu.cn/uploads/upload_cb85929dfea706edf0e52d55c2de6c61.png" alt=""></p><h2 id="BLIP">BLIP</h2><p>对于从图片到全景图，我们考虑的第一个技术路线是先从图片提取描述，这样就可以使用Text2Light模型，生成全景图。</p><p>图像描述相关的研究已经较为成熟，并且在帮助视障人士描绘环境物体等方面得到了应用。<br><img src="https://notes.sjtu.edu.cn/uploads/upload_546988233860a9d70e228c66437a2884.png" alt=""><br>我们使用的BLIP模型是一个全新的VLP框架，它可以统一视觉语言理解和生成，在各种下游任务上取得了稳定的性能改进，它使用多模态混合编码器-解码器，其中的语言建模损失以自回归的方式最大化文本的概率，激活了以图像为基础的文本解码器，能够生成给定图像的文本描述。</p><h2 id="CLIP">CLIP</h2><p>无论是Text2Light或是BLIP，都离不开CLIP的帮助，CLIP是一种基于对比文本-图像对的预训练方法或者模型，是一种基于对比学习的多模态模型。<br><img src="https://notes.sjtu.edu.cn/uploads/upload_fbdfa6c24adcb55042fb6cc25b604fae.png" alt=""></p><h2 id="Stable-Diffusion">Stable-Diffusion</h2><h3 id="扩散模型">扩散模型</h3><p><img src="https://notes.sjtu.edu.cn/uploads/upload_42983736bebbf3063e8a5aeded35d7df.png" alt=""><br>扩散模型受热力学启发，通过反转逐渐的噪声过程来学习生成数据。如上图所示，分为扩散过程（forward/diffusion process）和逆扩散过程（reverse process）。</p><ul><li>扩散过程（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mn>0</mn></msub><mo>−</mo><msub><mi>X</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">X_0 - X_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>）：逐步对图像加噪声，这一逐步过程可以认为是参数化的马尔可夫过程。</li><li>逆扩散过程（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>T</mi></msub><mo>−</mo><msub><mi>X</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">X_T - X_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>）：从噪声中反向推导，逐渐消除噪声以逆转生成图像。</li></ul><p>训练完成后，就能通过随机采样高斯噪声来生成图像了。实际上扩散模型和AE、VAE很类似，一个粗略的发展过程可以认为是AE–VAE–VQVAE–Diffusion，而扩散模型也逐步从DDPM–GLIDE–DALLE2–Stable Diffusion。</p><p><img src="https://notes.sjtu.edu.cn/uploads/upload_f4348ecf5ab96fdaf605e39aaa072921.png" alt=""></p><p>diffusion训练的核心就是取学习高斯噪声<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">z_θ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>之间的MSE均方误差。</p><h3 id="GLIDE（-Towards-Photorealistic-Image-Generation-and-Editing-with-Text-Guided-Diffusion-Models）"><strong>GLIDE</strong>（ Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models）</h3><p><img src="https://notes.sjtu.edu.cn/uploads/upload_7e3e36c3ff6305c43b642049839cdd5a.png" alt=""></p><p>OpenAI在2021提出了GLIDE模型，使用了无分类器引导的数据做扩散引导，在每一步的扩散过程中加入了Transformer的最后一个token作为条件。</p><p>GLIDE模型最重要的贡献在于它允许文本作为条件来生成图像。</p><h3 id="DALLE·2（Hierarchical-Text-conditional-Image-Generation-with-Clip-latents）"><strong>DALLE·2</strong>（Hierarchical Text-conditional Image Generation with Clip latents）</h3><p><img src="https://notes.sjtu.edu.cn/uploads/upload_8f57de79d991ad28b7a225b4167f2ed2.png" alt=""><br>DALLE2的模型结构如图，其中生成图像的扩散过程是基于GLIDE实现的。</p><ul><li>虚线上半部分是预训练好的CLIP。一侧输入文本，一侧是图像，用于得到表征。</li><li>虚线下半部分是text-to-image的生成过程。这一过程是二阶的过程，即文本变图像特征，再特性特征变图像。首先文本特征输入autoregressive或者diffusion prior以得到初步的图像特征（实验证明diffusion效率更高，因此一般选用diffusion），然后该特征会进一步作为condition到反向扩散模型中生成最后的图片。</li></ul><p>值得注意的是 GLIDE 模型以两种方式使用投影的 CLIP 文本嵌入。第一种是将它们添加到 GLIDE 现有的时间步嵌入中，第二种是通过创建四个额外的上下文 token，它们连接到 GLIDE 文本编码器的输出序列。</p><h3 id="Stable-Diffusion（High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models）"><strong>Stable-Diffusion</strong>（High-Resolution Image Synthesis with Latent Diffusion Models）</h3><p><img src="https://notes.sjtu.edu.cn/uploads/upload_61ee3dbce74c0a24873fc439db9c9351.png" alt=""></p><p>Stable-Diffusion是一个基于Latent Diffusion Models（潜在扩散模型，LDMs）的文图生成（text-to-image）模型。<br>构成Stable Diffusion的三个主要组成部分：</p><ul><li><strong>ClipText</strong>：用于对输入进行文本编码</li><li><strong>UNet + Scheduler</strong>：在信息(潜在)空间中逐步处理/传播信息。</li><li><strong>Autoencoder Decoder</strong>：使用处理过的信息数组绘制最终图像。</li></ul><p>为了加快图像生成过程，Stable-Diffusion运行的扩散过程不是在像素图像本身，而是在图像的压缩版本。这种压缩(以及后来的解压缩/绘制)是通过自动编码器完成的。自动编码器使用编码器将图像压缩到潜在空间，然后使用解码器仅使用压缩信息重建图像。</p><h2 id="风格迁移">风格迁移</h2><p>针对传入的原图和全景图风格差异过大的问题，考虑采用风格迁移的方式保留全景图的内容。</p><p>Gatys等人在2015年首先使用深度学习进行艺术画风格学习。输入一张内容图和一张风格图，输出一张保留内容图的内容和风格图的风格的图片。</p><p>在卷积神经网络CNN中，高层特征代表着图像的内容，由此为了保留图像的内容，定义内容损失函数为欧氏距离：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>p</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mi>l</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></munder><mo stretchy="false">(</mo><msubsup><mi>F</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>i</mi></msubsup><mo>−</mo><msubsup><mi>P</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>i</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L_{content}(\vec p,\vec x,l)=\frac{1}{2}\sum_{i,j}(F^i_{ij}-P^i_{ij})^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">co</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">p</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1522em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 53.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 1110.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2077em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 53.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 1110.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359c-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.7352em;vertical-align:-1.4138em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8747em;"><span style="top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2578em;vertical-align:-0.3831em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8747em;"><span style="top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p><p>风格特征在CNN中为低层特征，利用Gram矩阵定义风格损失函数如下：</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>G</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mo>=</mo><munder><mo>∑</mo><mi>k</mi></munder><msubsup><mi>F</mi><mrow><mi>i</mi><mi>k</mi></mrow><mi>l</mi></msubsup><msubsup><mi>F</mi><mrow><mi>j</mi><mi>k</mi></mrow><mi>l</mi></msubsup><mspace linebreak="newline"></mspace><msub><mi>E</mi><mi>l</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mn>4</mn><msubsup><mi>N</mi><mi>l</mi><mn>2</mn></msubsup><msubsup><mi>M</mi><mi>l</mi><mn>2</mn></msubsup></mrow></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mi>j</mi></mrow></munder><mo stretchy="false">(</mo><msubsup><mi>G</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mo>−</mo><msubsup><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mspace linebreak="newline"></mspace><msub><mi>L</mi><mrow><mi>s</mi><mi>t</mi><mi>y</mi><mi>l</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>0</mn></mrow><mi>L</mi></munderover><msub><mi>w</mi><mi>l</mi></msub><msub><mi>E</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">G^l_{ij}=\sum_k F^l_{ik}F^l_{jk}\\E_l=\frac{1}{4N^2_lM^2_l}\sum_{ij}(G^l_{ij}-A^l_{ij})^2\\L_{style}(\vec a, \vec x) = \sum^L_{l=0}w_lE_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2822em;vertical-align:-0.3831em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3521em;vertical-align:-1.3021em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">ik</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">jk</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.7352em;vertical-align:-1.4138em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">4</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959em;"><span style="top:-2.3987em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959em;"><span style="top:-2.3987em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9873em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2822em;vertical-align:-0.3831em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">a</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 53.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 1110.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359c-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2077em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 53.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 1110.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359c-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>总损失为内容损失与风格损失的加权和。</p><p>Luan在CVPR2017上发表的Deep Photo Style Transfer论文中提出一种对照片（摄影作品）的风格迁移方法，在损失函数中引入由拉普拉斯矩阵得出的正则项。先使用ResNet对原图和风格图进行语义分割，生成一些遮罩（mask）并增强神经网络的风格算法，输入到VGG19卷积神经网络中。</p><p>我们使用该方法尝试对全景图效果进行优化，效果如下，其中中间为风格图（客户端输入图片），左侧为内容图（根据输入图片生成的六面图），右侧为风格迁移的输出：<br><img src="https://notes.sjtu.edu.cn/uploads/upload_687ef12e0a48d538d911068a0e6d43ac.png" alt=""></p><p>整体效果尚可，但是存在语义分割不精确导致细节失真，且运行时间长的问题，因此风格迁移部分作为系统可选的模块。</p><p>此外，最近流行的生成式模型（CycleGAN等）可以在没有风格图输入的情况下进行风格迁移，且运行速度较快，但是由于需要时间和精力收集数据集进行训练，我们没有采用该方法。</p><h2 id="最终方案">最终方案</h2><p><img src="https://notes.sjtu.edu.cn/uploads/upload_98980a1a00677c9a550c66e96830c4ea.png" alt=""><br>最终我们采用的方案是：</p><ol><li>输入一张图片或者文字，如果是图片的话通过CLIP+BLIP获取该图的语义信息</li><li>通过Text2Light，输入该语义生成全景图</li><li>讲全景图根据极坐标转化为六方格图，提取出其接缝有问题的部分</li><li>将接缝问题图和mask一同传入diffusion中进行重绘，获得最后的成品图</li></ol><p>最后的图片返回至unity中可以通过我们写的脚本直接转化为mat格式供客户端展示。详细运行流程可以观看我们的演示视频。</p><h2 id="参考文献">参考文献</h2><ol><li>Radford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger and Ilya Sutskever. “Learning Transferable Visual Models From Natural Language Supervision.” International Conference on Machine Learning (2021).</li><li>Chen, Zhaoxi, Guangcong Wang and Ziwei Liu. “Text2Light: Zero-Shot Text-Driven HDR Panorama Generation.” ACM Trans. Graph. 41 (2022): 195:1-195:16.</li><li>Gatys, Leon A., Alexander S. Ecker and Matthias Bethge. “Image Style Transfer Using Convolutional Neural Networks.” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016): 2414-2423.</li><li>Luan, Fujun, Sylvain Paris, Eli Shechtman and Kavita Bala. “Deep Photo Style Transfer.” 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017): 6997-7005.</li><li>Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., … &amp; Sutskever, I. (2021). Learning transferable visual models from natural language supervision. arXiv preprint arXiv:2103.00020</li><li>Nichol, Alex, et al. “Glide: Towards photorealistic image generation and editing with text-guided diffusion models.” arXiv preprint arXiv:2112.10741 (2021).</li><li>Ho, Jonathan, Ajay Jain, and Pieter Abbeel. “Denoising diffusion probabilistic models.” Advances in Neural Information Processing Systems 33 (2020): 6840-6851.</li><li>Ramesh, Aditya, et al. “Hierarchical text-conditional image generation with clip latents.” arXiv preprint arXiv:2204.06125 (2022).</li><li>Rombach, Robin, et al. “High-resolution image synthesis with latent diffusion models.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>技术</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>大年初一 旧的开始</title>
    <link href="/2023/01/22/new-year/"/>
    <url>/2023/01/22/new-year/</url>
    
    <content type="html"><![CDATA[<p>回想了一下去年的这个时候 刚刚大三上结束 整理完图形学最后的报告后开始捣鼓服务器<br>把自己暑假搞的卡牌对战后端和后来做的网页项目全部在服务器上搭了一遍 还到处找人去展示<br>结果一个星期之后 新鲜感退却了之后服务器就基本没有维护了<br>直到开学了才发现同学们该刷题的早就刷了一个寒假 该准备的简历也早都准备好了<br>这才开始拼命刷题复习弄博客<br>之后是疫情封城 投简历 笔试面试 对自己找不到工作的无尽焦虑<br>最终还是莉莉丝给了我一份正式的offer<br>从暑假开始不断接触视频动捕 人体骨骼 动画重定向 再之后慢慢开始到diffusion和AIGC<br>一年下来才发现这份实习让我学习的东西实在宝贵 我也算是慢慢踏入了机器学习的门槛<br>来年接着好好准备毕设和最后的实习 9月份之后崭新入学 重新梳理一遍自己的所学知识<br>这里就先为之后的学习记录先做好铺垫了 之前整理过的文档也会慢慢更新在这里<br>希望明年依旧有所收获</p>]]></content>
    
    
    
    <tags>
      
      <tag>日常</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
